{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "- Range of Motion</br>\n",
    "  Using the MoCap data, determine how far the phone / head is moved for each gesture (broken down by head and phone, linear and angular, and participant)\n",
    "- Time Taken</br>\n",
    "  How long it takes for the participant to perform a specific gesture (broken down by gesture and direction)</br>\n",
    "  How to determine when gesture started vs finished (2 metrics, from first line to last, from motion started to stopped (threshold for motion?))\n",
    "- Frame Containing Face</br>\n",
    "  Use Open CV, how determine rotated faces, manually mark frames between frames with faces marked as not having any?</br>\n",
    "  TensorFlow model for face detection?\n",
    "- Average Sample Rate for each data source (image, imu, ignore MoCap as fixed rate), also split by attempt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import csv\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import itertools as iter\n",
    "\n",
    "DATA_PATH = # replace with path\n",
    "\n",
    "CSV_FIELD_NAMES = [\n",
    "    'MS_DELTA', 'RELATIVE_IMAGE_PATH', 'LINEAR_X', 'LINEAR_Y', 'LINEAR_Z', 'ROTATION_X', 'ROTATION_Y', 'ROTATION_Z', 'ROTATION_SCALAR', \n",
    "    'LINEAR_X_DELTA', 'LINEAR_Y_DELTA', 'LINEAR_Z_DELTA', 'ROTATION_X_DELTA', 'ROTATION_Y_DELTA', 'ROTATION_Z_DELTA', 'ROTATION_SCALAR_DELTA'\n",
    "]\n",
    "# CSV_CLASSIFIER_FIELD_NAMES = []\n",
    "CSV_REGRESSION_FIELD_NAMES = [\n",
    "    'HEAD_X', 'HEAD_Y', 'HEAD_Z', 'HEAD_PITCH', 'HEAD_ROLL', 'HEAD_YAW', 'PHONE_X', 'PHONE_Y', 'PHONE_Z', 'PHONE_PITCH', 'PHONE_ROLL', 'PHONE_YAW', \n",
    "    'HEAD_X_DELTA', 'HEAD_Y_DELTA', 'HEAD_Z_DELTA', 'HEAD_PITCH_DELTA', 'HEAD_ROLL_DELTA', 'HEAD_YAW_DELTA', \n",
    "    'PHONE_X_DELTA', 'PHONE_Y_DELTA', 'PHONE_Z_DELTA', 'PHONE_PITCH_DELTA', 'PHONE_ROLL_DELTA', 'PHONE_YAW_DELTA'\n",
    "]\n",
    "\n",
    "def get_preprocessed_image(image_path):\n",
    "    cv.imread()\n",
    "    pass\n",
    "\n",
    "# Need to batch (chunk size is hyper-param)\n",
    "# probs want to over-crank to get cases where have less frames (e.g. keep every x frames, average data between that)\n",
    "def data_generator(paths, chunk_size=10, pick_rate=[1,2,3,4], regression_output=False):\n",
    "    config = \n",
    "    if average_until_new_image:\n",
    "        data_paths = shuffle(data_paths + [(path, True) for path in data_paths])\n",
    "    \n",
    "    for path in data_paths:\n",
    "        with open(path, 'r') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "            reader.__next__() # skip header\n",
    "            for row in reader:\n",
    "                \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files to process: 1029\n",
      "Testing paths: 206, Training: 576, Validation: 247\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path('/mnt/e/Uni/CM50175/Study/data')\n",
    "def get_data_filepaths(root_dir):\n",
    "    for participant_path in root_dir.iterdir():\n",
    "        if participant_path.is_dir():\n",
    "            synced_data_path = participant_path / 'synced_data'\n",
    "            for participant_data_path in synced_data_path.iterdir():\n",
    "                if participant_data_path.is_dir():\n",
    "                    for gesture in participant_data_path.iterdir():\n",
    "                        for direction in gesture.iterdir():\n",
    "                            if len(list((direction / 'images').iterdir())) > 0:\n",
    "                                csv = synced_data_path / f'{participant_data_path.name}_{gesture.name}_{direction.name}.csv'\n",
    "                                if Path(csv).is_file():\n",
    "                                    yield csv\n",
    "\n",
    "file_paths = list(get_data_filepaths(DATA_PATH))\n",
    "print(f'Number of files to process: {len(file_paths)}')\n",
    "\n",
    "train_val_paths, test_paths = train_test_split(file_paths, test_size=0.2, random_state=28)\n",
    "train_paths, val_paths = train_test_split(train_val_paths, test_size=0.3, random_state=16)\n",
    "\n",
    "print(f\"Testing paths: {len(test_paths)}, Training: {len(train_paths)}, Validation: {len(val_paths)}\")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(data_generator(train_paths))\n",
    "val_ds = tf.data.Dataset.from_generator(data_generator(val_paths))\n",
    "test_ds = tf.data.Dataset.from_generator(data_generator(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('diss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "669cd1d434545bf58bc3edc245c962a9a1da7f94287adf7d982064b9c729a651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
